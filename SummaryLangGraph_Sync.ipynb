{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e8ae8e6-918c-4659-8436-539176fb95a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting summarization...\n",
      "\n",
      "ðŸ§© Map step\n",
      "\n",
      "ðŸ§ª Reduce step\n",
      "\n",
      "âœ… Final Summary Output:\n",
      "\n",
      "Here's a consolidated summary of the key points from the loan agreement and promissory note:\n",
      "\n",
      "**Loan Agreement and Promissory Note Summary**\n",
      "\n",
      "A loan agreement and promissory note were executed on July 1, 2010, between Wharton Capital, LLC (the \"Lender\") and Sangrine Corp (the \"Borrower\"). The key points are as follows:\n",
      "\n",
      "*   Loan amount: $27,500.00\n",
      "*   Interest rate: 7% per annum\n",
      "*   Repayment terms:\n",
      "    *   Three separate payments will be made according to a specific schedule\n",
      "    *   No details provided for the first and second payment amounts\n",
      "    *   No details provided for the third payment amount\n",
      "\n",
      "Please note that this summary only covers the critical points mentioned in the original text and may not include all aspects of the loan agreement and promissory note.\n"
     ]
    }
   ],
   "source": [
    "# SummaryLangGraph_Sync.ipynb\n",
    "\n",
    "# Cell 1: Imports\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import List, Dict, TypedDict\n",
    "\n",
    "# ---- Load PDF ----\n",
    "pdf_path = \"Sample_Loan.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# Define the shared state\n",
    "class State(TypedDict):\n",
    "    docs: List[Document]\n",
    "    accumulated_summaries: List[str]\n",
    "    current_summary: str\n",
    "    final_summary: str\n",
    "\n",
    "# Initialize the model\n",
    "llm = Ollama(model=\"llama3.2\")  # or \"mistral\" or any model you prefer\n",
    "\n",
    "map_prompt = PromptTemplate.from_template(\n",
    "    \"Write an excellent summary of the following, covering every critical point:\\n\\n{context}\"\n",
    ")\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "reduce_prompt = PromptTemplate.from_template(\n",
    "    \"The following is a set of summaries:\\n{summaries}\\nTake these and distill it into a final, consolidated summary of the main themes.\"\n",
    ")\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# Define map node\n",
    "def map_node(state: State) -> State:\n",
    "    print(\"ðŸ§© Map step\")\n",
    "    doc = state[\"docs\"].pop(0)\n",
    "    # print(f\"   - Processing doc: {doc.page_content}\")\n",
    "    result = map_chain.invoke({\"context\": doc.page_content})\n",
    "    # print(f\"   âœ… Got summary: {result['text']}\")\n",
    "    state[\"accumulated_summaries\"].append(result[\"text\"])\n",
    "    return state\n",
    "\n",
    "# Define reduce node\n",
    "def reduce_node(state: State) -> State:\n",
    "    print(\"\\nðŸ§ª Reduce step\")\n",
    "    combined = \"\\n\".join(state[\"accumulated_summaries\"])\n",
    "    result = reduce_chain.invoke({\"summaries\": combined})\n",
    "    # print(f\"   âœ… Final summary: {result['text']}\")\n",
    "    state[\"final_summary\"] = result[\"text\"]\n",
    "    return state\n",
    "\n",
    "# Define condition for looping\n",
    "def should_continue(state: State) -> str:\n",
    "    return \"map\" if len(state[\"docs\"]) > 0 else \"reduce\"\n",
    "\n",
    "# Build the graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"map\", map_node)\n",
    "graph_builder.add_node(\"reduce\", reduce_node)\n",
    "graph_builder.set_conditional_entry_point(should_continue)\n",
    "graph_builder.add_edge(\"map\", \"reduce\")\n",
    "graph_builder.add_edge(\"reduce\", END)\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Run it synchronously\n",
    "initial_state: State = {\n",
    "    \"docs\": docs.copy(),\n",
    "    \"accumulated_summaries\": [],\n",
    "    \"current_summary\": \"\",\n",
    "    \"final_summary\": \"\",\n",
    "}\n",
    "\n",
    "print(\"ðŸš€ Starting summarization...\\n\")\n",
    "final_state = graph.invoke(initial_state)\n",
    "print(\"\\nâœ… Final Summary Output:\\n\")\n",
    "print(final_state[\"final_summary\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18d006-5401-4af6-8e86-9d436d183f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
